---
title: "Recovery survey exploration"
format: html
editor: visual
---

## Initial exploration of recovery survey data

Explore recovery surveys to examine emergent trends, survey effort, data structure, etc.

## Part 1: explore quadrat data

Step 1: set directories and load data. Note: data are stored on a secured server that requires authentication.

```{r}
rm(list=ls())
require(librarian)
librarian::shelf(tidyverse, ggplot2, RColorBrewer, vegan)

datdir <- "/Volumes/seaotterdb$/kelp_recovery/data/MBA_kelp_forest_database"

quad_dat <- read_csv(file.path(datdir,"processed/recovery/recovery_quad.csv"))

urch_size_dat <- read_csv(file.path(datdir,"processed/recovery/recovery_urch_sizefq.csv")) 

kelp_dat <- read_csv(file.path(datdir,"processed/recovery/recovery_kelpswath.csv")) 

gonad_dat <- read_csv(file.path(datdir, "processed/dissection_data_recovery.csv")) 

```

Step 2: prep derived datasets

```{r}

#Step 1: aggregate quad data to transect level
quad_transect <- quad_dat %>%
                  #drop substrate for now, we'll handle this later
                  select(-substrate, -quadrat)%>%
                  group_by(site, site_type, survey_date, latitude, longitude,
                           zone, transect) %>%
                  dplyr::summarise(across(everything(), ~ mean(.x, na.rm = TRUE)))

#check nrow
nrow(quad_transect)
nrow(kelp_dat)
#wooo they match!

#Step 2: aggregate dissection data to transect level
gonad_zone <- gonad_dat %>%
                  #drop substrate for now, we'll handle this later
                  select(site, site_type, zone, species, test_diameter_mm,
                         gonad_index)%>%
                  group_by(site, site_type, zone, species) %>%
                  dplyr::summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
                pivot_wider(
                  names_from = species,
                  values_from = c(test_diameter_mm, gonad_index)
                )

#step 3: join data 
merge_dat <- quad_transect %>%
              left_join(., gonad_zone, by = c("site", "site_type", "zone")) %>%
              left_join(., kelp_dat, by = c("survey_date","site","site_type", "zone","transect"
                                            ,"latitude", "longitude"
                                            )) %>%
  #reorder
  select(site, site_type, survey_date, latitude, longitude, zone, transect,depth_m, relief_cm,
          risk_cm, risk_index, purple_urchin_densitym2, purple_urchin_densitym2, red_urchin_densitym2, red_urchin_conceiledm2, tegula_densitym2, pomaulax_densitym2, 
          test_diameter_mm_purple_urchin,test_diameter_mm_red_urchin, gonad_index_purple_urchin, gonad_index_red_urchin, n_macro_plants_20m2,    macro_stipe_density_20m2, macro_stipe_sd_20m2, density20m2_purps_on_kelp, density20m2_ptecal, density20m2_eisarb, density20m2_nerlue, density20m2_lamset,              density20m2_cancer_spp, density20m2_lamstump,density20m2_macstump, everything())


```

Explore sampling effort for each site

```{r}
#| echo: false


# Reorder zone to put Shallow before Deep
quad_dat <- quad_dat %>%
  mutate(zone = factor(zone, levels = c("Shallow", "Deep")))

# Count unique quadrats per site, site type, zone, and transect
quadrat_counts <- quad_dat %>%
  group_by(site, site_type, zone, transect) %>%
  summarise(num_quadrats = n_distinct(quadrat), .groups = "drop")

# Bar plot with Dark2 color palette
ggplot(quadrat_counts, aes(x = num_quadrats, y = as.factor(transect), fill = site_type)) +
  geom_col(position = "dodge") +
  facet_grid(zone ~ site, scales = "free_y") +  # Facet by zone and site
  scale_fill_manual(values = brewer.pal(3, "Dark2")) +  # Use Dark2 colors
  labs(
    x = "Number of sampled quadrats",
    y = "Transect",
    title = "Number of quadrats per site, site type, zone, and transect",
    fill = "Site Type"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    strip.text = element_text(face = "bold"),  # Bold facet labels
    panel.grid.major.y = element_blank(),      # Clean up y-axis grid
    panel.grid.minor = element_blank(),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10, angle = 0, hjust = 0.5)
  )


```

Check for missing or zero values

```{r}
#| echo: false


# Check missing values
missing_summary <- quad_dat %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "num_missing")

# Check zeros in density and percent cover columns
zero_summary <- quad_dat %>%
  summarise(across(where(is.numeric), ~sum(. == 0))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "num_zeros")

print(zero_summary)

```

Plot sea urchin density by zone and substrate type

```{r}
ggplot(quad_dat, aes(x = substrate, y = purple_urchin_densitym2, fill = site_type)) +
  geom_boxplot() +
  facet_wrap(~ zone) +
  labs(
    x = "Substrate type",
    y = "Purple sea urchin density (m²)",
    title = "Purple sea urchin density by substrate and zone"
  ) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
# Pivot data for easier boxplot creation
density_data <- quad_dat %>%
  select(site, zone, starts_with("purple_urchin_densitym2"), starts_with("red_urchin_densitym2")) %>%
  pivot_longer(cols = starts_with("purple_urchin_densitym2"):starts_with("red_urchin_densitym2"), 
               names_to = "density_type", values_to = "density")

# Boxplot to check for outliers
ggplot(density_data, aes(x = density_type, y = density)) +
  geom_boxplot(outlier.colour = "red", fill = "lightgray") +
  facet_wrap(~ zone) +
  labs(
    x = "Density Type",
    y = "Density (m²)",
    title = "Boxplot of Urchin Densities by Zone"
  ) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Part 2: explore site type differences

First, lets take a look at any biological (in terms of the cover and density of macroalgae and inverts) differences between forests, barrens, and incipient forests. We will normalize the data to handle both density and cover.

```{r}
# ------------------------------
# Step 0: Load Required Libraries
# ------------------------------
library(vegan)
library(ggplot2)

# ------------------------------
# Step 1: Define the Community Variables
# ------------------------------
# Include any columns starting with "cov_" plus the additional biological measures.
community_vars <- c(
  grep("^cov_", colnames(merge_dat), value = TRUE),
  "red_urchin_densitym2",
  "red_urchin_conceiledm2",
  "tegula_densitym2",
  "pomaulax_densitym2",
  "test_diameter_mm_purple_urchin",
  "test_diameter_mm_red_urchin",
  "gonad_index_purple_urchin",
  "gonad_index_red_urchin",
  "n_macro_plants_20m2",
  "macro_stipe_density_20m2",
  "density20m2_purps_on_kelp",
  "density20m2_ptecal",
  "density20m2_eisarb",
  "density20m2_nerlue",
  "density20m2_lamset",
  "density20m2_cancer_spp",
  "density20m2_lamstump",
  "density20m2_macstump",
  "purple_urchin_conceiledm2"
)

# Subset the data to include only the community variables
community_data <- merge_dat[, community_vars]

# ------------------------------
# Step 2: Remove Missing Data and Constant Variables
# ------------------------------
# Remove rows with missing values in community_data
complete_idx <- complete.cases(community_data)
community_data_complete <- community_data[complete_idx, ]
meta_complete <- merge_dat[complete_idx, ]  # Contains site_type, etc.

# Remove constant columns (those with zero variance) to avoid issues during scaling
non_constant <- sapply(community_data_complete, function(x) sd(x, na.rm = TRUE)) > 0
community_data_complete <- community_data_complete[, non_constant]

# Ensure site_type is a factor
meta_complete$site_type <- as.factor(meta_complete$site_type)

# ------------------------------
# Step 3: Standardize the Data
# ------------------------------
# Standardize the data (z-scores: mean=0, sd=1)
community_data_std <- scale(community_data_complete)

# ------------------------------
# Step 4: Run NMDS on the Standardized Community Data
# ------------------------------
set.seed(123)  # For reproducibility
nmds_comm <- metaMDS(community_data_std, distance = "euclidean", trymax = 100)
cat("NMDS stress:", nmds_comm$stress, "\n")

# Extract NMDS site scores (each transect is one point)
nmds_scores <- as.data.frame(scores(nmds_comm, display = "sites"))
nmds_scores$site_type <- meta_complete$site_type

# ------------------------------
# Step 5: Plot NMDS with Group Ellipses Using ggplot2
# ------------------------------
p_nmds <- ggplot(nmds_scores, aes(x = NMDS1, y = NMDS2, color = site_type)) +
  geom_point(size = 3) +
  stat_ellipse(type = "norm", level = 0.68, linetype = 2) +  # ~1 SD ellipse
  labs(title = "NMDS of Biological Community Data",
       x = "NMDS1", y = "NMDS2",
       color = "Site Type") +
  theme_minimal()
print(p_nmds)

# ------------------------------
# Step 6: Global PERMANOVA Analysis
# ------------------------------
# Compute Euclidean distance matrix on the standardized data
comm_dist <- dist(community_data_std, method = "euclidean")

# Run global PERMANOVA to test overall differences among site types
global_perm <- adonis2(comm_dist ~ meta_complete$site_type, permutations = 999)
print(global_perm)

# ------------------------------
# Step 7: Pairwise PERMANOVA with Corrected Indexing
# ------------------------------
pairwise_adonis2 <- function(dist_matrix, groups, perm = 999, p.adjust.method = "bonferroni") {
  groups <- as.factor(groups)
  pair_list <- combn(levels(groups), 2, simplify = FALSE)
  results <- data.frame()
  
  # Convert the 'dist' object to a full matrix for subsetting
  dmat <- as.matrix(dist_matrix)
  
  for (pair in pair_list) {
    # Select indices of observations in the current pair
    idx <- groups %in% pair
    # Subset the full distance matrix and convert back to a "dist" object
    dpair <- as.dist(dmat[idx, idx])
    ad_res <- adonis2(dpair ~ groups[idx], permutations = perm)
    res <- data.frame(Group1 = pair[1],
                      Group2 = pair[2],
                      F.Model = ad_res$F[1],
                      R2 = ad_res$R2[1],
                      p.value = ad_res$`Pr(>F)`[1])
    results <- rbind(results, res)
  }
  results$p.adjusted <- p.adjust(results$p.value, method = p.adjust.method)
  return(results)
}

pairwise_results <- pairwise_adonis2(comm_dist, meta_complete$site_type, perm = 999)
print(pairwise_results)

# ------------------------------
# Step 8: SIMPER Analysis to Determine What Drives Differences
# ------------------------------
simper_results <- simper(community_data_std, group = meta_complete$site_type, permutations = 999)
simper_summary <- summary(simper_results)
print(simper_summary)



```

Now lets separate density and cover, sticking with biological data only, for now.

```{}
```

```{r}
# ------------------------------
# Step 0: Load Libraries, Define my_theme, and nice_name()
# ------------------------------
library(vegan)
library(ggplot2)
library(dplyr)
library(grid)  # For arrow()

my_theme <- theme(axis.text = element_text(size = 7, color = "black"),
                  axis.title = element_text(size = 8, color = "black"),
                  legend.text = element_text(size = 7, color = "black"),
                  legend.title = element_text(size = 8, color = "black"),
                  strip.text = element_text(size = 8, hjust = 0, face = "bold", color = "black"),
                  strip.background = element_blank(),
                  plot.title = element_text(size = 9, color = "black"),
                  plot.tag = element_text(size = 9, color = "black", face = 'bold'),
                  panel.grid.major = element_blank(), 
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank(), 
                  axis.line = element_line(colour = "black"),
                  legend.key.size = unit(0.5, "cm"),
                  legend.background = element_rect(fill = alpha('blue', 0)))

# Function to clean up variable names:
nice_name <- function(x) {
  # Remove the "cov_" prefix, if present
  x <- gsub("^cov_", "", x)
  # Remove the "density20m2_" prefix, if present (for density vectors)
  x <- gsub("^density20m2_", "", x)
  x <- gsub("m2", "", x)
  # Replace underscores with spaces
  x <- gsub("_", " ", x)
  # Convert to lowercase and then capitalize the first letter
  x <- tolower(x)
  x <- paste0(toupper(substr(x,1,1)), substr(x,2, nchar(x)))
  return(x)
}

# ------------------------------
# Step 1: Helper Function for Pairwise PERMANOVA
# ------------------------------
pairwise_adonis2 <- function(dist_matrix, groups, perm = 999, p.adjust.method = "bonferroni") {
  groups <- as.factor(groups)
  pair_list <- combn(levels(groups), 2, simplify = FALSE)
  results <- data.frame()
  dmat <- as.matrix(dist_matrix)  # Convert dist object to full matrix
  for (pair in pair_list) {
    idx <- groups %in% pair
    dpair <- as.dist(dmat[idx, idx])
    ad_res <- adonis2(dpair ~ groups[idx], permutations = perm)
    res <- data.frame(Group1 = pair[1],
                      Group2 = pair[2],
                      F.Model = ad_res$F[1],
                      R2 = ad_res$R2[1],
                      p.value = ad_res$`Pr(>F)`[1])
    results <- rbind(results, res)
  }
  results$p.adjusted <- p.adjust(results$p.value, method = p.adjust.method)
  return(results)
}

# Define multipliers for envfit vectors:
cover_multiplier <- 1.2   # For cover data vectors
density_multiplier <- 0.26 # For density data vectors

# ====================================================
# COVER DATA ANALYSIS WITH VECTORS (Bray–Curtis distance)
# ====================================================
cat("### Cover Data Analysis ###\n")

## (a) Subset and Clean Cover Data
cover_data <- merge_dat[, grep("^cov_", colnames(merge_dat))]
complete_idx_cover <- complete.cases(cover_data)
cover_data_complete <- cover_data[complete_idx_cover, ]
meta_cover <- merge_dat[complete_idx_cover, ]
meta_cover$site_type <- as.factor(meta_cover$site_type)
non_constant_cover <- sapply(cover_data_complete, function(x) sd(x, na.rm = TRUE)) > 0
cover_data_complete <- cover_data_complete[, non_constant_cover]

## (b) NMDS on Raw Cover Data Using Bray–Curtis Distance
set.seed(123)
nmds_cover <- metaMDS(cover_data_complete, distance = "bray", trymax = 100)
cat("NMDS stress (Cover):", nmds_cover$stress, "\n")
scores_cover <- as.data.frame(scores(nmds_cover, display = "sites"))
scores_cover$site_type <- meta_cover$site_type

## (c) Plot NMDS for Cover Data: Option to show only centroids
centroids_cover <- scores_cover %>%
  group_by(site_type) %>%
  summarize(NMDS1 = mean(NMDS1), NMDS2 = mean(NMDS2))
p_cover <- ggplot(scores_cover, aes(x = NMDS1, y = NMDS2)) +
  stat_ellipse(aes(color = site_type), type = "norm", linetype = 1, size = 1) +
  # Uncomment the next line if you want to see all individual points:
  # geom_point(aes(color = site_type, shape = site_type), size = 3, alpha = 0.5) +
  geom_point(data = centroids_cover, aes(x = NMDS1, y = NMDS2, color = site_type, shape = site_type),
             size = 4, alpha = 1) +
  scale_color_brewer(palette = "Dark2") +
  labs(title = "",
       x = "NMDS1", y = "NMDS2", color = "Site Type", shape = "Site Type") +
  theme_bw() + my_theme
print(p_cover)

## (d) Global and Pairwise PERMANOVA on Cover Data
dist_cover <- vegdist(cover_data_complete, method = "bray")
perm_cover <- adonis2(dist_cover ~ meta_cover$site_type, permutations = 999)
print(perm_cover)
pairwise_cover <- pairwise_adonis2(dist_cover, meta_cover$site_type, perm = 999)
print(pairwise_cover)

## (e) (Optional) SIMPER Analysis for Cover Data
simper_cover <- simper(cover_data_complete, group = meta_cover$site_type, permutations = 999)
simper_summary_cover <- summary(simper_cover)
print(simper_summary_cover)

## (f) Overlay Vectors on Cover NMDS Plot
# Physical Vectors (Blue)
physical_vars <- meta_cover[, c("relief_cm", "risk_index")]
envfit_phys <- envfit(nmds_cover, physical_vars, permutations = 999)
phys_scores <- as.data.frame(scores(envfit_phys, display = "vectors"))
phys_scores$variable <- rownames(phys_scores)
phys_sig <- phys_scores[envfit_phys$vectors$pvals < 0.05, ]
cat("Significant physical vectors (blue):\n")
print(phys_sig)

# Biological Vectors (Black) from cover data
envfit_bio <- envfit(nmds_cover, cover_data_complete, permutations = 999)
bio_scores <- as.data.frame(scores(envfit_bio, display = "vectors"))
bio_scores$variable <- rownames(bio_scores)
bio_sig <- bio_scores[envfit_bio$vectors$pvals < 0.05, ]
cat("Significant biological vectors (black):\n")
print(bio_sig)

# Update vector names using nice_name() for better display
phys_sig$nice_variable <- nice_name(phys_sig$variable)
bio_sig$nice_variable  <- nice_name(bio_sig$variable)

# Increase vector lengths using cover_multiplier
phys_sig$NMDS1 <- phys_sig$NMDS1 * cover_multiplier
phys_sig$NMDS2 <- phys_sig$NMDS2 * cover_multiplier
bio_sig$NMDS1  <- bio_sig$NMDS1 * cover_multiplier
bio_sig$NMDS2  <- bio_sig$NMDS2 * cover_multiplier

p_cover_final <- p_cover +
  geom_segment(data = phys_sig, inherit.aes = FALSE,
               aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.2, "cm")), color = "blue", size = 1) +
  geom_text(data = phys_sig, inherit.aes = FALSE,
            aes(x = NMDS1, y = NMDS2, label = nice_variable),
            color = "blue", vjust = 1.5, size = 3) +
  geom_segment(data = bio_sig, inherit.aes = FALSE,
               aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.2, "cm")), color = "black", size = 1) +
  geom_text(data = bio_sig, inherit.aes = FALSE,
            aes(x = NMDS1, y = NMDS2, label = nice_variable),
            color = "black", vjust = -0.5, size = 3)
print(p_cover_final)

# ====================================================
# DENSITY DATA ANALYSIS WITH VECTORS (Using Euclidean distance)
# ====================================================
cat("\n### Density Data Analysis ###\n")
density_vars <- c(
  "red_urchin_densitym2",
  "red_urchin_conceiledm2",
  "tegula_densitym2",
  "pomaulax_densitym2",
  "test_diameter_mm_purple_urchin",
  "test_diameter_mm_red_urchin",
  "gonad_index_purple_urchin",
  "gonad_index_red_urchin",
  "n_macro_plants_20m2",
  "macro_stipe_density_20m2",
  #"density20m2_purps_on_kelp",
  "density20m2_ptecal",
  "density20m2_eisarb",
  "density20m2_nerlue",
  "density20m2_lamset",
  #"density20m2_cancer_spp",
  "density20m2_lamstump",
  "density20m2_macstump",
  "purple_urchin_densitym2",
  "purple_urchin_conceiledm2"
)
density_data <- merge_dat[, density_vars]
complete_idx_density <- complete.cases(density_data)
density_data_complete <- density_data[complete_idx_density, ]
meta_density <- merge_dat[complete_idx_density, ]
meta_density$site_type <- as.factor(meta_density$site_type)
non_constant_density <- sapply(density_data_complete, function(x) sd(x, na.rm = TRUE)) > 0
density_data_complete <- density_data_complete[, non_constant_density]

## NMDS on Raw Density Data Using Euclidean Distance
set.seed(123)
nmds_density <- metaMDS(density_data_complete, distance = "euclidean", trymax = 100)
cat("NMDS stress (Density):", nmds_density$stress, "\n")
scores_density <- as.data.frame(scores(nmds_density, display = "sites"))
scores_density$site_type <- meta_density$site_type

## For Density, show only centroids
centroids_density <- scores_density %>%
  group_by(site_type) %>%
  summarize(NMDS1 = mean(NMDS1), NMDS2 = mean(NMDS2))
p_density <- ggplot(scores_density, aes(x = NMDS1, y = NMDS2)) +
  stat_ellipse(aes(color = site_type), type = "norm", linetype = 1, size = 1) +
  # Uncomment the next line to show individual points:
  # geom_point(aes(color = site_type, shape = site_type), size = 3, alpha = 0.5) +
  geom_point(data = centroids_density, aes(x = NMDS1, y = NMDS2, color = site_type, shape = site_type),
             size = 4, alpha = 1) +
  scale_color_brewer(palette = "Dark2") +
  labs(title = "",
       x = "NMDS1", y = "NMDS2", color = "Site Type", shape = "Site Type") +
  theme_bw() + my_theme
print(p_density)

## Global and Pairwise PERMANOVA on Density Data
dist_density <- dist(density_data_complete, method = "euclidean")
perm_density <- adonis2(dist_density ~ meta_density$site_type, permutations = 999)
print(perm_density)
pairwise_density <- pairwise_adonis2(dist_density, meta_density$site_type, perm = 999)
print(pairwise_density)

## (Optional) SIMPER Analysis for Density Data
simper_density <- simper(density_data_complete, group = meta_density$site_type, permutations = 999)
simper_summary_density <- summary(simper_density)
print(simper_summary_density)

## Overlay Vectors on Density NMDS Plot
# Physical Vectors (Blue)
physical_vars_density <- meta_density[, c("relief_cm", "risk_index")]
envfit_phys_density <- envfit(nmds_density, physical_vars_density, permutations = 999)
phys_scores_density <- as.data.frame(scores(envfit_phys_density, display = "vectors"))
phys_scores_density$variable <- rownames(phys_scores_density)
phys_sig_density <- phys_scores_density[envfit_phys_density$vectors$pvals < 0.05, ]
cat("Significant physical vectors for density (blue):\n")
print(phys_sig_density)

# Biological Vectors (Black) using density data
envfit_bio_density <- envfit(nmds_density, density_data_complete, permutations = 999)
bio_scores_density <- as.data.frame(scores(envfit_bio_density, display = "vectors"))
bio_scores_density$variable <- rownames(bio_scores_density)
bio_sig_density <- bio_scores_density[envfit_bio_density$vectors$pvals < 0.05, ]
cat("Significant biological vectors for density (black):\n")
print(bio_sig_density)

# Use nice_name() to clean up names; this will now remove "density20m2_" if present
phys_sig_density$nice_variable <- nice_name(phys_sig_density$variable)
bio_sig_density$nice_variable  <- nice_name(bio_sig_density$variable)

# Multiply density vectors by density_multiplier
phys_sig_density$NMDS1 <- phys_sig_density$NMDS1 * density_multiplier
phys_sig_density$NMDS2 <- phys_sig_density$NMDS2 * density_multiplier
bio_sig_density$NMDS1 <- bio_sig_density$NMDS1 * density_multiplier
bio_sig_density$NMDS2 <- bio_sig_density$NMDS2 * density_multiplier

p_density_final <- p_density +
  geom_segment(data = phys_sig_density, inherit.aes = FALSE,
               aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.2, "cm")), color = "indianred", size = 1) +
  geom_text(data = phys_sig_density, inherit.aes = FALSE,
            aes(x = NMDS1, y = NMDS2, label = nice_variable),
            color = "indianred", vjust = 1.5, size = 3) +
  geom_segment(data = bio_sig_density, inherit.aes = FALSE,
               aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               arrow = arrow(length = unit(0.2, "cm")), color = "gray70", size = 1,
               alpha = 0.5) +
  geom_text(data = bio_sig_density, inherit.aes = FALSE,
            aes(x = NMDS1, y = NMDS2, label = nice_variable),
            color = "black", vjust = -0.5, 
             nudge_x = 0.001, nudge_y = 0.001, size = 3)+
  #coord_cartesian(clip = "off") +
  theme(plot.margin = unit(c(1, 1, 1, 1), "cm"))
print(p_density_final)

ggsave(p_density_final, filename=file.path("/Users/jossmith/Downloads", "Fig1_NMDS_sitetype.png"), width=8, height=6, units="in", dpi=600)



```

Toy with LDA

```{r}

# Load required libraries
library(MASS)
library(ggplot2)

# Ensure site_type is a factor
merge_dat$site_type <- as.factor(merge_dat$site_type)

# Option 1: Using a pre-selected subset of predictors that you believe are important.
# Here we choose key predictors related to physical characteristics and biological densities.
# You may modify these predictors based on your understanding of the ecology.
lda_model <- lda(site_type ~ relief_cm + risk_index + 
                   purple_urchin_densitym2 + red_urchin_densitym2 + 
                   tegula_densitym2 + cov_crustose_coralline + cov_encrusting_red,
                 data = merge_dat)

# Print LDA model details to see discriminant function coefficients and explained proportions
print(lda_model)

# Obtain the predicted linear discriminant values for each observation
lda_pred <- predict(lda_model)
# Create a data frame of LDA scores and add site_type for plotting
lda_df <- data.frame(lda_pred$x, site_type = merge_dat$site_type)

# Plot the first two linear discriminants
ggplot(lda_df, aes(x = LD1, y = LD2, color = site_type)) +
  geom_point(size = 3) +
  labs(title = "LDA: Separation of Site Types",
       x = "Linear Discriminant 1",
       y = "Linear Discriminant 2")







# Extract the scaling (coefficients) matrix from the LDA model
lda_coeff <- lda_model$scaling
print(lda_coeff)  # Examine the coefficients

# Optionally, visualize the absolute coefficients
library(reshape2)
library(ggplot2)

# Convert the matrix to a data frame for easier plotting
ld_loadings <- as.data.frame(lda_coeff)
ld_loadings$Variable <- rownames(ld_loadings)

# Reshape the data frame for ggplot2 (melt the data)
ld_loadings_melt <- melt(ld_loadings, id.vars = "Variable", 
                         variable.name = "Discriminant", value.name = "Coefficient")

# Create a bar plot of the absolute value of coefficients for each discriminant
ggplot(ld_loadings_melt, aes(x = reorder(Variable, abs(Coefficient)), y = Coefficient, fill = Discriminant)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  labs(title = "LDA: Predictor Contributions by Discriminant",
       x = "Predictor",
       y = "Coefficient Value")



```

Toy with permanova

```{r}
# Load necessary library
library(vegan)

# Select only numeric variables (and filter out constant variables)
numeric_vars <- merge_dat[, sapply(merge_dat, is.numeric)]
non_constant_vars <- numeric_vars[, sapply(numeric_vars, function(x) sd(x, na.rm = TRUE)) > 0]

# Scale the data (optional, but often useful)
scaled_vars <- scale(non_constant_vars)

# Compute a distance matrix (Euclidean distance is used here)
diss_matrix <- dist(scaled_vars)

# Run the global PERMANOVA
global_perm <- adonis2(diss_matrix ~ site_type, data = merge_dat, permutations = 999)
print(global_perm)


dispersion <- betadisper(diss_matrix, merge_dat$site_type)
anova(dispersion)  # Tests for differences in dispersion among groups










# Load required library
library(vegan)

# ------------------------
# 1. Remove Missing Values
# ------------------------
# Remove rows with missing values from the scaled data.
complete_ind <- complete.cases(scaled_vars)
scaled_vars_complete <- scaled_vars[complete_ind, ]
merge_dat_complete <- merge_dat[complete_ind, ]

# ------------------------
# 2. Define the Pairwise PERMANOVA Function Using adonis2
# ------------------------
pairwise.adonis2 <- function(x, factors, sim.method = 'euclidean', 
                             p.adjust.m = 'bonferroni', permutations = 999, ...) {
  # Ensure the vegan package is loaded
  library(vegan)
  
  # Get unique pairs of levels from the factors
  factor_levels <- unique(factors)
  combinations <- combn(factor_levels, 2)
  
  # Prepare a storage data.frame
  results <- data.frame()
  
  for (i in 1:ncol(combinations)) {
    # Create a logical index for rows belonging to the two groups in this pair
    current_pair <- factors %in% combinations[, i]
    # Perform PERMANOVA with adonis2
    ad_result <- adonis2(x[current_pair, ] ~ factors[current_pair],
                         permutations = permutations, 
                         method = sim.method, ...)
    
    # Extract F, R2 and p-value from the first row of the results table
    temp <- data.frame(
      group1 = combinations[1, i],
      group2 = combinations[2, i],
      F.Model = ad_result$F[1],
      R2 = ad_result$R2[1],
      p.value = ad_result$`Pr(>F)`[1]
    )
    
    results <- rbind(results, temp)
  }
  
  # Adjust p-values for multiple comparisons
  results$p.adjusted <- p.adjust(results$p.value, method = p.adjust.m)
  return(results)
}

# ------------------------
# 3. Run Pairwise PERMANOVA Comparisons
# ------------------------
pairwise_results <- pairwise.adonis2(scaled_vars_complete, 
                                     merge_dat_complete$site_type, 
                                     sim.method = "euclidean", 
                                     p.adjust.m = "bonferroni")

# Display the pairwise PERMANOVA results
print(pairwise_results)



```

TEst SIMPER

```{r}
# Load vegan if not already loaded
library(vegan)

# Run SIMPER on the complete scaled variables, grouped by site_type.
simper_results <- simper(scaled_vars_complete, merge_dat_complete$site_type)

# View a summary for a specific comparison, e.g., BAR vs. INCIP:
summary(simper_results, ordered = TRUE, group = "FOR-INCIP")


```

Test NMDS on cover

```{r}
# Load required libraries
library(vegan)
library(ggplot2)
library(grid)      # For arrow unit specifications

### 1. Subset and prepare the cover data ###
# Extract only the cover variables (names beginning with "cov_")
cover_vars <- merge_dat[, grep("^cov_", colnames(merge_dat))]

# Remove rows with missing values in the cover data
complete_idx <- complete.cases(cover_vars)
cover_vars_complete <- cover_vars[complete_idx, ]
merge_dat_cover <- merge_dat[complete_idx, ]

### 2. Run NMDS on the cover data ###
set.seed(123)  # For reproducibility
# Use Bray-Curtis distance which is common for percent cover data.
nmds_cover <- metaMDS(cover_vars_complete, distance = "bray", trymax = 100, autotransform = FALSE)

# Display the stress value to assess goodness-of-fit
print(nmds_cover$stress)

### 3. Extract NMDS scores into a data frame ###
# 'scores' extracts the site (observation) scores; we assume 2 dimensions.
nmds_scores <- as.data.frame(scores(nmds_cover, display = "sites"))
# Add the group (site_type) information
nmds_scores$site_type <- merge_dat_cover$site_type

### 4. Fit environmental variables using envfit ###
# Choose a set of environmental predictors you suspect might be driving differences.
env_vars <- merge_dat_cover[, c("relief_cm", "risk_index", 
                                "purple_urchin_densitym2", 
                                "red_urchin_densitym2", 
                                "tegula_densitym2")]

envfit_result <- envfit(nmds_cover, env_vars, permutations = 999)
print(envfit_result)

# Extract only the vectors (for numeric variables) that are significant (p < 0.05)
sig_idx <- which(envfit_result$vectors$pvals < 0.05)
if(length(sig_idx) > 0){
  sig_vectors <- envfit_result$vectors$arrows[sig_idx, , drop = FALSE]
  # Convert to a data frame and add variable names
  vectors_df <- as.data.frame(sig_vectors)
  vectors_df$Variable <- rownames(vectors_df)
  
  # Scale the vectors for plotting.
  # Choose a multiplier that makes the arrows visually appropriate relative to your NMDS scores.
  multiplier <- 0.2
  vectors_df$NMDS1 <- vectors_df$NMDS1 * multiplier
  vectors_df$NMDS2 <- vectors_df$NMDS2 * multiplier
} else {
  vectors_df <- NULL
}

### 5. Plot the NMDS using ggplot2 with ellipses and environmental vectors ###
# Create the base scatterplot of NMDS scores colored by site_type
p <- ggplot(nmds_scores, aes(x = NMDS1, y = NMDS2, color = site_type)) +
  geom_point(size = 3) +
  # Add ellipses around each group; stat_ellipse with level = 0.68 approximates 1 standard deviation
  stat_ellipse(type = "norm", level = 0.68, linetype = 2) +
  labs(title = "NMDS of Cover Data with Group Ellipses and Envfit Vectors",
       x = "NMDS1", y = "NMDS2",
       color = "Site Type") +
  theme_minimal()

# Add the envfit vectors if any are significant
if(!is.null(vectors_df)){
  p <- p +
    geom_segment(data = vectors_df,
                 aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
                 arrow = arrow(length = unit(0.25, "cm")),
                 color = "black", size = 1) +
    geom_text(data = vectors_df,
              aes(x = NMDS1, y = NMDS2, label = Variable),
              color = "black", vjust = -0.5)
}

# Print the final plot
print(p)


```
